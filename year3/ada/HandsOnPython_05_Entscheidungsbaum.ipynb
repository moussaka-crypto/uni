{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WP5lilNxPUXd"
   },
   "source": [
    "### Erstellen eines Prognosemodells für den Energieverbrauch\n",
    "\n",
    "\n",
    "Dieses Notebook zeigt\n",
    "- wie man mithilfe eines Entscheidungsbaums ein Vorhersagemodell für den Energieverbrauch erstellen kann\n",
    "- wie man die Modell-Performance bewerten kann\n",
    "- wie man die Modell-Performance optimieren kann (Hyperparameteroptimierung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzf7QuIEPUXr"
   },
   "outputs": [],
   "source": [
    "### Bibliotheken einbinden\n",
    "\n",
    "## Datenanalyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Plotten\n",
    "import matplotlib.pyplot as plt\n",
    "# zeige Plots in Zellen des Notebooks an\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "# setze seaborn style defaults und Default-Wert für Plotgröße\n",
    "sns.set(rc={'figure.figsize':(20, 10)}) \n",
    "\n",
    "## Maschinelles Lernen\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.tree import export_text\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaPKqauxQCbE"
   },
   "outputs": [],
   "source": [
    "# Google Drive mounten\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnbMA2yDPUXw"
   },
   "source": [
    "## Aufgabe 1\n",
    "Lesen Sie den Datensatz Energieverbrauch.csv ein und geben Sie sich die ersten Spalten aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvHjZMUaPUXy"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/My Drive/Energieverbrauch.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLJIhG0WPUX1"
   },
   "source": [
    "## Aufgabe 2\n",
    "- Sie wollen ein Vorhersagemodell für den Energiebedarf erstellen.\n",
    "- Indizieren Sie dazu zunächst das Dataframe mit dem Zeitstempel. \n",
    "- Vergessen Sie dabei nicht, das Datenformat der Spalte Date falls nötig zu ändern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiKgkkpwPUX3"
   },
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzQcBr3LPUX5"
   },
   "source": [
    "## Aufgabe 3\n",
    "- Für das Vorhersagemodell wollen Sie folgende Merkmale heranziehen: \n",
    "    Jahr, Monat, Wochentag (0,1,2,3...,6 für Mo-So)\n",
    "- Solche zeitlichen Merkmale können Sie ganz leicht mithilfe des Zeitstempel-Index generieren. \n",
    "- Für den Wochentag wurde das unten beispielhaft schon durchgeführt. \n",
    "- Fügen Sie auf ähnliche Weise zwei weitere Spalten mit den Merkmalen Jahr und Monat ein. Hinweis: Verwenden Sie dazu die Attribute year und month des index.\n",
    "- Geben Sie sich Teile des Dataframes aus und inspizieren Sie die neu hinzugefügten Merkmale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TS5XTXrJPUX7"
   },
   "outputs": [],
   "source": [
    "data['Weekday'] = data.index.weekday\n",
    "\n",
    "# Das hier noch anpassen\n",
    "#data['Year'] = data.index. ...\n",
    "#data['Month'] = data.index. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkT4nDocPUX9"
   },
   "source": [
    "## Aufgabe 4\n",
    "- Weiterhin wollen Sie das Merkmal Wochenende 0/1 generieren. \n",
    "- Wie das funktioniert, sieht man in der unteren Zelle.\n",
    "- Gehen Sie den Code durch und versuchen Sie zu verstehen, was passiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVTlB-o1PUX_"
   },
   "outputs": [],
   "source": [
    "data['Weekend'] = [0 if x < 5 else 1 for x in data.index.weekday]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu3ZoaKbPUYB"
   },
   "source": [
    "## Aufgabe 5\n",
    "- Unten kommt eine Zelle mit einer Hilfsfunktion. Sie müssen die Zelle einfach nur ausführen. Die Funktion an sich müssen Sie nicht verändern. \n",
    "- Versuchen Sie zu verstehen, was passiert. Was macht die Hilfsfunktion?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seDbB9JrRYei"
   },
   "source": [
    "Antwort: Die Hilfsfunktion 'generate_sets' teilt den übergebenen DataFrame in Trainings-, Validierungs- und Testmengen auf, im Verhältnis 60% (Trainingsmenge), 20% (Validierungsmenge) und 20% (Testmenge). Dabei wird der DataFrame zufällig aufgeteilt. Anschließend werden die Zielvariablen (Labels) und die Merkmalsvektoren für jede Menge getrennt zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dje3PbgyPUYD"
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktion\n",
    "def generate_sets(df): \n",
    "    \n",
    "    # Spalte df auf in Trainings-, Validierungs- und Testmenge in den Anteilen 60%, 20%, 20%\n",
    "    df_train, df_validate, df_test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])        \n",
    "        \n",
    "    # Auswahl der Label durch Auswahl der entsprechenden Spalten                 \n",
    "    y_train = df_train['Consumption']\n",
    "    y_validate = df_validate['Consumption']\n",
    "    y_test = df_test['Consumption']\n",
    "        \n",
    "    # Merkmale nicht in des Modell einbeziehen und somit die jeweiligen Spalten aus dem Datensatz entfernen\n",
    "    X_train = df_train.drop(['Consumption','Year'], axis=1)\n",
    "    X_validate = df_validate.drop(['Consumption','Year'], axis=1)\n",
    "    X_test = df_test.drop(['Consumption','Year'], axis=1)                                                                          \n",
    "    \n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1u1G44aPUYE"
   },
   "source": [
    "## Aufgabe 6\n",
    "- Oben in der Hilfsfunktion wird das Merkmal 'Year' aus den Datensätzen entfernt und nicht in das Modell einbezogen. Warum macht das Sinn?\n",
    "- Weiterhin wird aus X_train/validate/test die Spalte \"Consumption\" gelöscht. Wieso macht das Sinn?\n",
    "- Wozu braucht man Trainings-, Validierungs- und Testmenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjaNopoSRctq"
   },
   "source": [
    "Antwort: Das Merkmal 'Year' wird aus den Datensätzen entfernt, weil es in diesem Fall wahrscheinlich keine nützliche Information für die Vorhersage des Energieverbrauchs enthält. Die Spalte \"Consumption\" wird aus X_train/validate/test gelöscht, weil es die Zielvariable ist, die wir vorhersagen möchten, und sie nicht als Merkmal in der Vorhersage verwendet werden sollte. Trainings-, Validierungs- und Testmengen werden verwendet, um ein Modell zu trainieren, seine Performance zu bewerten und seine Generalisierungsfähigkeit auf unbekannten Daten zu testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0i_TEQoPUYF"
   },
   "outputs": [],
   "source": [
    "# Datensatz aufteilen in Trainings-, Validierungs- und Testmenge mit der Hilfsfunktion:\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = generate_sets(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odcd6Ap8PUYH"
   },
   "source": [
    "## Aufgabe 7\n",
    "- Es folgt eine Hilfsfunktion zum Trainieren eines Entscheidungsbaum und der graphischen Ausgabe des trainierten Baumes.\n",
    "- Auch an dieser Funktion müssen Sie nichts ändern.\n",
    "- Vielleicht verstehen Sie Teile der Funktion?\n",
    "- Schauen Sie sich an, wie man Funktionen zum leichteren Verständnis mittels ''' ''' kommentieren kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8sokImMPUYH"
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktion 2\n",
    "def train_decision_tree(X_train, y_train, min_samples_split = 2, min_samples_leaf = 1, output=False):\n",
    "    '''\n",
    "    Hilfsfunktion zum Trainieren eines Entscheidungsbaumes auf einer Trainingsmenge.\n",
    "    \n",
    "    Inputs: \n",
    "    X_train (df): Dataframe mit den Merkmalsvektoren der Trainingsmenge\n",
    "    y_train (df): Dataframe mit den Labeln der Trainingsmenge\n",
    "    min_samples_split (float oder int): wenn float, prozentualer Mindestanteil an Samples in jedem Split,\n",
    "                                        wenn int, Mindestanzahl Samples in jedem Split\n",
    "    min_samples_split (float oder int): wenn float, prozentualer Mindestanteil an Samples in jedem Blatt des Entscheidungsbaumes,\n",
    "                                        wenn int, Mindestanzahl Samples in jedem Blatt\n",
    "    output (bool): ob eine Ausgabe erzeugt werden soll (Die Ausgabe enthält die Regeln des Entscheidungsbaumes und eine graphische \n",
    "                   Darstellung des Entscheidungsbaumes)\n",
    "                   \n",
    "    Outputs:\n",
    "    dtr: ein auf der Trainingsmenge trainierter Entscheidungsbaum, der nachfolgend zur Prognose verwendet werden kann          \n",
    "    '''\n",
    "    \n",
    "    # Spaltennamen (=Namen der Merkmale) für später speichern\n",
    "    feature_names = list(X_train.columns)\n",
    "    \n",
    "    # Dataframes in numpy arrays konvertieren, da der Entscheidungsbaum das als Input benötigt\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    #Entscheidungsbaum mit bestimmten Hyperparametern (min_samples_splkit und min_samples_leaf intialisieren)\n",
    "    dtr = DecisionTreeRegressor(random_state = 0, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "    \n",
    "    # Entscheidungsbaum trainieren\n",
    "    dtr.fit(X_train, y_train)\n",
    "    \n",
    "    # Optionale Ausgabe generieren\n",
    "    if output:\n",
    "        \n",
    "        rules = export_text(dtr, feature_names = feature_names)\n",
    "        print(rules)\n",
    "        print('Folgende Merkmale waren verfügbar:', feature_names)\n",
    "        \n",
    "        with plt.style.context('classic'):\n",
    "            plt.figure(figsize=(20,10))\n",
    "            tree.plot_tree(dtr, filled=True, impurity=True, rounded=True, feature_names=feature_names)\n",
    "    \n",
    "    return dtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I5jnNDzPUYJ"
   },
   "source": [
    "### Aufgabe 8:\n",
    "- Als nächstes wollen wir einen Entscheidungsbaum auf dem Trainingsdatensatz trainieren. \n",
    "- Dazu wird die Hilfsfunktion train_decision_tree herangezogen. \n",
    "- Diese enthält die Parameter min_samples_split und min_samples_leaf\n",
    "- Was bedeuten diese Parameter? Versuchen Sie dies mithilfe der Dokumentation zu klären:  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- Was passiert wenn Sie diese Parameter verändern?\n",
    "- Führen Sie die Funktion in der untenstehenden Zelle mehrfach aus und variieren Sie dabei z.B. min_samples_split zwischen 2 und 2000. Probieren Sie mindestens 10 verschiedene Werte in diesem Bereich aus und betrachten den entstehenden Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1SIfLHVPUYK"
   },
   "outputs": [],
   "source": [
    "# Datensatz aufteilen in Trainings-, Validierungs- und Testmenge mit Hilfsfunktion generate_sets\n",
    "trained_decision_tree = train_decision_tree(X_train, y_train, min_samples_split = 900, min_samples_leaf = 1, output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxGTNod4PUYL"
   },
   "source": [
    "- Es folgt eine weitere Hilfsfunktion zur Vorhersage des Energieverbrauchs mithilfe des zuvor trainierten Entscheidungsbaums\n",
    "- Auch an dieser Funktion müssen Sie nichts ändern und wir sprechen sie gemeinsam durch.\n",
    "- Wichtig: mit dieser Funktion kann man testen, wie gut die Vorhersage auf der Validierungsmenge funktioniert, siehe Aufgabe 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hgk2VD87PUYM"
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktion 3\n",
    "def predict_with_decision_tree(dtr, X_val, y_val, output=True):\n",
    "    '''\n",
    "    Hilfsfunktion zur Erstellung einer Vorhersage auf Basis eines trainierten Entscheidungsbaumes und zur Ausgabe der Gütemaße.\n",
    "    \n",
    "    Inputs: \n",
    "    dtr: ein zuvor auf einer Trainingsmenge trainierter Entscheidungsbaum, der zur Prognose verwendet werden kann  \n",
    "    X_val (df): Dataframe mit den Merkmalsvektoren der Validierungsmenge\n",
    "    y_val (df): Dataframe mit den Labeln der Validierungsmenge\n",
    "    output (bool): ob eine print-Ausgabe erzeugt werden soll (enthält Gütemaße), standardmäßig auf True.\n",
    "   \n",
    "    Outputs:\n",
    "    y_pred (np.array): Vorhersage des Entscheidungsbaumes für die Merkmalsvektoren der Validierungsmenge   \n",
    "    metrics_dict (dict): Dictionary mit den Metriken zur Bewertung der Vorhersagegüte\n",
    "    '''  \n",
    "    \n",
    "    # Vorhersage für Validierungsmenge mit Entscheidungsbaum generieren\n",
    "    y_pred = dtr.predict(X_val)\n",
    "    \n",
    "    ## Metriken zur Bewertung der Vorhersagegüte berechnen\n",
    "    # Absoluten Fehler berechnen: Betrag der Differenz zwischen Vorhersage und den tatsächlichen Label der Validierungsmenge\n",
    "    abs_errors = abs(y_pred - y_val)\n",
    "\n",
    "    # Mean Absolute Error (MAE) durch Bilden des Mittelwertes berechnen\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    \n",
    "    # Relativen Mean Absolute Error (MAE) durch Bilden des Mittelwertes berechnen\n",
    "    mae_rel = mae/np.mean(y_val)\n",
    "    \n",
    "    # Mean Absolut Percentage Error (MAPE) berechnen\n",
    "    mape = np.mean(abs_errors/y_val)\n",
    "    \n",
    "    # Mean Squared Error \n",
    "    mse = mean_squared_error(y_val, y_pred) \n",
    "    \n",
    "    # Root Mean Squared Error\n",
    "    rmse = np.sqrt(mse) / np.mean(y_val)\n",
    "    \n",
    "    metrics_dict = {'mae': mae,\n",
    "                    'mse': mse,\n",
    "                    'mae%': mae_rel*100,\n",
    "                    'mape%': mape*100,\n",
    "                    'rmse%': rmse*100\n",
    "                   }\n",
    "    \n",
    "    if output:\n",
    "        print('Mittelwert der wahren Label', round(np.mean(y_val), 2))\n",
    "        print('MAE', round(mae, 4))\n",
    "        print('MSE', round(mse, 4))\n",
    "        print('MAE%', mae_rel*100)\n",
    "        print('MAPE%', mape*100)\n",
    "        print('RMSE%', rmse*100)\n",
    "            \n",
    "    return y_pred, metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpWbczQ4PUYN"
   },
   "source": [
    "## Aufgabe 8\n",
    "- Mit dem trainierten Entscheidungsbaum (trained_decision_tree) werden im nächsten Schritt Vorhersagen für die Validierungsmenge erstellt\n",
    "- Die Vorhersagen des Entscheidungsbaums werden innerhalb von Hilfsfunktion 3 mit den tatsächlichen Labeln der Validierungmenge verglichen\n",
    "- Verschiedene Metriken zur Bewertung der Güte der Regression können herangezogen werden, s. Vorlesung\n",
    "- Was bedeutet die einzelnen Metriken, die nach Ausführen der nächsten Zelle ausgegeben werden?\n",
    "- Ist das Prognosemodell gut?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyc2uSrPRrLC"
   },
   "source": [
    "Antwort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsVsx3a-PUYO"
   },
   "outputs": [],
   "source": [
    "# Erzeuge mit dem Trainierten Entscheidungsbaum eine Vorhersage für das Validierungsset\n",
    "y_pred, metrics_dict = predict_with_decision_tree(trained_decision_tree, X_val, y_val, output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oi4P5McEPUYP"
   },
   "source": [
    "## Aufgabe 9\n",
    "- Wir wollen ein gute Wahl für den Hyperparameter min_samples_split treffen.\n",
    "- Dafür gibt es Hilfsfunktion 4. Können Sie erkennen, was in der Hilfsfunktion passiert?\n",
    "- Versuchen Sie einen Kommentar zu verfassen, der die Hilfsfunktion beschreibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQHtOhNpPUYQ"
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktion 4\n",
    "def optimize_hyperparam(X_train, y_train, X_val, y_val, metric='mae%'):\n",
    "    '''\n",
    "    Hilfsfunktion zur ..... \n",
    "    \n",
    "    Inputs: \n",
    "    ...\n",
    "    ...\n",
    "   \n",
    "    Outputs:\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    # Anzahl der Beobachtungen bestimmen, funktioniert über Zeilenanzahl von X_train.\n",
    "    number_of_samples = X_train.shape[0]\n",
    "    \n",
    "    # Noch leere Liste für Metriken erstellen, die später sukzessive gefüllt wird.\n",
    "    metrics_list = []\n",
    "    \n",
    "    # Optimalen Wert für Metrik mit großer Zahl initialisieren\n",
    "    best_metric = 100000\n",
    "    \n",
    "    ## Schleife zum Optimieren des Hyperparameters min_samples split\n",
    "    # min_samples_split wird auf Werte zwischen 2 und int(np.floor(1/5*number_of_samples)) gesetzt und in Einserschritten erhöht.\n",
    "    # Für jedes gesetzte min_samples_split wird ein Entscheidungsbaum trainiert \n",
    "    # und dessen Performance anhand der Validierungsmenge getestet\n",
    "    for min_samples_split in range(2, int(np.floor(1/3*number_of_samples))):\n",
    "        \n",
    "        # Trainieren eines Entscheidungsbaums mit bestimmtem Wert für min_samples_split \n",
    "        decision_tree = train_decision_tree(X_train, y_train, min_samples_split = min_samples_split, output=False)\n",
    "        \n",
    "        # Auswerten der Performance des Entscheidungsbaums durch Einsetzen der Validierungsmenge \n",
    "        # und Vergleich der vorhergesagten Label y_pred mit den wahren Labeln y_val\n",
    "        y_pred, metrics_dict = predict_with_decision_tree(decision_tree, X_val, y_val, output=False)\n",
    "        metrics_list.append((min_samples_split, metrics_dict))\n",
    "        \n",
    "        # Finden des optimalen Werts für min_samples_split\n",
    "        if metrics_dict[metric] <= best_metric:\n",
    "            best_metric = metrics_dict[metric]\n",
    "            best_min_split = min_samples_split \n",
    "            \n",
    "    ## Plotten der Ergebnisse \n",
    "    # Linienplot mit (x=Werte für min_samples_split, y=Wert der ausgewählten Metrik)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.lineplot(x=[i[0] for i in metrics_list], y=[i[1][metric] for i in metrics_list])\n",
    "    # Vertikale Linie bei x=best_min_split\n",
    "    plt.axvline(x=best_min_split, color='k', linestyle = '--')\n",
    "    # Horizontale Linie bei dazugehörigem y, sowie Legende erzeugen\n",
    "    plt.axhline(y=best_metric, color='k', linestyle = '--', \n",
    "                label='Bester Wert für min_samples_split: ' + str(best_min_split) + '\\n' + metric + ': ' + str(best_metric))\n",
    "    plt.legend()\n",
    "    \n",
    "    # Ausgabe der Funktion\n",
    "    return metrics_list, best_metric, best_min_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hifsuDSuPUYT"
   },
   "source": [
    "## Aufgabe 10\n",
    "- Führen Sie die obige Zelle aus, sodass die Funktion optimize_hyperparam() definiert wird.\n",
    "- Wenden Sie anschließend die Funktion optimize_hyperparam() an durch ausführen der unteren Zelle und bestimmen Sie metrics_list, best_metric und best_min_split\n",
    "- Wie interpretieren Sie den erzeugten Plot? Wie sollten Sie den Hyperparameter min_samples_split setzen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjt84xzdPUYW"
   },
   "outputs": [],
   "source": [
    "metrics_list, best_metric, best_min_split = optimize_hyperparam(\"accuracy\") # in die Klammer muss noch etwas rein, was?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkf8a2APPUYW"
   },
   "source": [
    "## Aufgabe 11\n",
    "- Trainieren Sie erneut einen Entscheidungsbaum und setzten Sie dabei gezielt min_samples_split auf den gefundenen optimalen Wert, indem Sie die unten stehende Funktion ausführen.\n",
    "- Was sagen Sie zu dem Ergebnis?\n",
    "- Wenn Sie mit einem Fehler %mae <= 7% zufrieden wären, welche Werte für best_min_split könnten Sie setzen? Welchen Wert würden Sie wählen, um eine gute Interpretierbarkeit des Baumes durch den Menschen zu gewährleisten?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC1GnNVdRz9K"
   },
   "source": [
    "Antwort: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td0xhZR3PUYX"
   },
   "outputs": [],
   "source": [
    "# Trainiere Entescheidungsbaum mit min_samples_split = best_min_split\n",
    "# best_min_split ist dabei der beste gefundene Wert für diesen Hyperparameter aus der Optimierungs oben.\n",
    "decision_tree_large = train_decision_tree(X_train, y_train, min_samples_split = best_min_split, output=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8kQhJH3PUYY"
   },
   "outputs": [],
   "source": [
    "# Trainiere einen kleineren Entscheidungsbaum durch setzen eines anderen Wertes für min_samples_split, sodass mae% vertretbar\n",
    "decision_tree_smaller = train_decision_tree(X_train, y_train, min_samples_split=10, output=True)\n",
    "\n",
    "# Diese Zeile wieder einkommentieren und anpassen\n",
    "#decision_tree_smaller = train_decision_tree(X_train, y_train, min_samples_split = TODO anpassen, output=True) \n",
    "\n",
    "\n",
    "# Überprüfe Performance auf Validierungsmenge\n",
    "y_pred, metrics_dict = predict_with_decision_tree(decision_tree_smaller, X_val, y_val, output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3rEtMj6PUYZ"
   },
   "source": [
    "## Aufgabe 12\n",
    "- Prüfen Sie die Performance des großen und des kleinen Entscheidungsbaumes auf dem Testset.\n",
    "- Wie interpretieren Sie die Ergebnisse? Wäre der kleine Entscheidungsbaum vertretbar?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0zkeWGMR460"
   },
   "source": [
    "Antwort: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUIo3_jDPUYZ"
   },
   "outputs": [],
   "source": [
    "# Performance des großen Entscheidungsbaums auf dem Testset\n",
    "y_pred, metrics_dict = predict_with_decision_tree(decision_tree_large, X_test, y_test, output=True)\n",
    "\n",
    "# Ausgabe einer leeren Zeile für die Übersichtlichkeit\n",
    "print()\n",
    "\n",
    "# Performance des kleinen Entscheidungsbaums auf dem Testset\n",
    "y_pred, metrics_dict = predict_with_decision_tree(decision_tree_smaller, X_test, y_test, output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FDla9YOPUYa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
